---
title: "Computing per-cluster statistics (examples only)"
format:
  html:
    toc: true
---

`massSight` intentionally does **not** enforce any particular normalization or outcome model.
This page provides small, copy-pasteable examples for computing per-cluster statistics after clustering.

## Recommended v1 defaults (binary outcome)

- transform intensities with `log1p`
- effect size: Hedges’ g (case vs control)
- p-value: z-test using Hedges’ g standard error

## Python example: per-study Hedges’ g + z-test

Assume you have:

- a sample×cluster matrix `X` (e.g., `clusters.cluster_expr[analysis_id]` from the clustering tutorial)
- a sample metadata table `endpoints` indexed by sample ID and containing a binary outcome `outcome` in `{0,1}`

```{python}
#| label: feature-stats-examples-functions
import math
from typing import Tuple

import numpy as np
import pandas as pd

def hedges_g(x_case: np.ndarray, x_ctrl: np.ndarray) -> Tuple[float, float]:
    x_case = np.asarray(x_case, dtype=float)
    x_ctrl = np.asarray(x_ctrl, dtype=float)
    x_case = x_case[np.isfinite(x_case)]
    x_ctrl = x_ctrl[np.isfinite(x_ctrl)]
    n1, n0 = int(x_case.size), int(x_ctrl.size)
    if n1 < 2 or n0 < 2:
        return np.nan, np.nan

    m1, m0 = float(np.mean(x_case)), float(np.mean(x_ctrl))
    s1, s0 = float(np.var(x_case, ddof=1)), float(np.var(x_ctrl, ddof=1))
    sp = math.sqrt(((n1 - 1) * s1 + (n0 - 1) * s0) / max(n1 + n0 - 2, 1))
    if not np.isfinite(sp) or sp <= 0:
        return np.nan, np.nan

    d = (m1 - m0) / sp
    j = 1.0 - (3.0 / (4.0 * (n1 + n0) - 9.0))
    g = j * d
    se = math.sqrt((n1 + n0) / (n1 * n0) + (g * g) / (2.0 * (n1 + n0 - 2)))
    return float(g), float(se)

def two_sided_z_pvalue(z: float) -> float:
    return float(math.erfc(abs(z) / math.sqrt(2.0)))

def per_cluster_stats(X: pd.DataFrame, endpoints: pd.DataFrame, *, outcome_col: str = "outcome") -> pd.DataFrame:
    if outcome_col not in endpoints.columns:
        raise ValueError(f"Missing {outcome_col!r} in endpoints.")
    endpoints = endpoints.reindex(X.index)
    y = endpoints[outcome_col].astype(int).to_numpy()

    logX = np.log1p(X.to_numpy(dtype=float))
    out = []
    cluster_ids = X.columns.astype(str).tolist()
    for j, cid in enumerate(cluster_ids):
        g, se = hedges_g(logX[y == 1, j], logX[y == 0, j])
        z = g / se if (se and np.isfinite(se) and se > 0) else np.nan
        p = two_sided_z_pvalue(z) if np.isfinite(z) else np.nan
        out.append({"cluster_id": cid, "hedges_g": g, "se": se, "z": z, "p": p})
    return pd.DataFrame(out).sort_values("p")

# Example:
# stats = per_cluster_stats(X, endpoints, outcome_col="outcome")
# stats.head()
```

```{python}
#| label: feature-stats-examples-demo
rng = np.random.default_rng(0)

X = pd.DataFrame(
    rng.lognormal(mean=2.0, sigma=0.6, size=(24, 6)),
    index=[f"s{i}" for i in range(24)],
    columns=[f"cluster_{j}" for j in range(6)],
)
endpoints = pd.DataFrame(
    {"outcome": rng.integers(0, 2, size=24)},
    index=X.index,
)

stats = per_cluster_stats(X, endpoints, outcome_col="outcome")
stats.head()
```
